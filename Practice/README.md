# Practice

æœ¬é¡µä¸ºä¸€äº›å¼€æºé¡¹ç›®çš„é›†ä¸­æ”¶å½•ä¸å®è·µå·¥ç¨‹é—®é¢˜è®°å½•æ€»ç»“



## ä¸€ã€é¡¹ç›®æ”¶å½•

1. é¢å‘å•†ç”¨åŒ–çš„LLMæ¨ç†æ¡†æ¶

| åç§°  | ç®€ä»‹       | åœ°å€    |åç«¯|
|:---:|:----: |:--- |:---:|
| vllm | å¿«é€Ÿä¸”æ˜“äºä½¿ç”¨çš„ LLM æ¨ç†å’ŒæœåŠ¡åº“ã€‚|[Link](https://docs.vllm.ai/en/stable/)|pytorch|
| LMDeploy | LMDeploy ç”± MMDeploy å’Œ MMRazor å›¢é˜Ÿè”åˆå¼€å‘ï¼Œæ˜¯æ¶µç›–äº† LLM ä»»åŠ¡çš„å…¨å¥—è½»é‡åŒ–ã€éƒ¨ç½²å’ŒæœåŠ¡è§£å†³æ–¹æ¡ˆ|[Link](https://github.com/InternLM/lmdeploy)|pytorch or [TurboMind](https://github.com/InternLM/lmdeploy/blob/main/docs/zh_cn/inference/turbomind.md)|
| LMDeploy-Jetson| å°†LMDeployç§»æ¤åˆ°NVIDIA Jetsonç³»åˆ—è¾¹ç¼˜è®¡ç®—å¡çš„éƒ¨ç½²æ•™ç¨‹ä»“åº“|[Link](https://github.com/BestAnHongjun/LMDeploy-Jetson?tab=readme-ov-file)|åŒä¸Š|
| LightLLM | çº¯pythonå¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†å’ŒæœåŠ¡æ¡†æ¶ï¼Œå…·æœ‰è½»é‡çº§è®¾è®¡ã€æ˜“æ‰©å±•ä»¥åŠé«˜æ€§èƒ½ç­‰ç‰¹ç‚¹ |[Link](https://github.com/ModelTC/lightllm)|python|
| TensorRT-LLM |Nvidia å®˜æ–¹llmæ¨ç†æ¡†æ¶ |[Link](https://github.com/NVIDIA/TensorRT-LLM)   |TensorRT |
| SGLang |é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹çš„å¿«é€ŸæœåŠ¡æ¡†æ¶ |[Link](https://github.com/sgl-project/sglang)   |pytroch |


2. é¢å‘è¾¹ç¼˜éƒ¨ç½²çš„LLMé¡¹ç›®


| åç§°  | ç®€ä»‹       | åœ°å€    |åç«¯|
|:---:|:----: |:--- |:---:|
| llama.cpp | Inference of Meta's LLaMA model (and others) in pure C/C++|[Link](https://github.com/ggerganov/llama.cpp)|ggml (C++)|
| llama2.c | Inference Llama 2 in one file of pure C |[Link](https://github.com/karpathy/llama2.c)| C|
| calm | CUDA/Metal accelerated language model inference |[Link](https://github.com/zeux/calm)| C|
| yalm |  LLM inference in C++/CUDA, no libraries except for I/O(ä¸“æ³¨äºåŸç†ã€ä»£ç å¯è¯»æ€§çš„ç§‘ç ”å®éªŒé¡¹ç›®) |[Link](https://github.com/andrewkchan/yalm)| C++|


## äºŒã€éƒ¨ç½²å­¦ä¹ è®°å½•

### 1. GGMLæ¡†æ¶

| åºå· | å†…å®¹    | åœ°å€    |çŠ¶æ€|
|:---:|:----: |:--- |:---:|
| 00 | Introduction of GGML and Manual Usage|[Link](./GGML_Home.md)|ğŸš§ Unfinished|
| 01 | GGML Manualï¼Œæºç å­¦ä¹ æ‰‹å†Œ|[Link](./GGML_guide.md)|ğŸ”¬Researching|
| 02 |  -  |-|-|

### 1. llama.cpp

| åºå· | å†…å®¹    | åœ°å€    |çŠ¶æ€|
|:---:|:----: |:--- |:---:|
| 00 | Build and Run|-|â˜ï¸Todo|
| 01 | GGML æ¡†æ¶|[Link](./GGML_Home.md)|ğŸ”¬Researching|
| 02 |Understanding how LLM inference works with llama.cpp  |[Link](https://www.omrimallis.com/posts/understanding-how-llm-inference-works-with-llama-cpp/)|Web Link|




### 2. vllm
